{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c6186b-e07b-4850-b67a-61034a1947db",
   "metadata": {},
   "source": [
    "# CycleGAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2938f037-e0a7-4bf9-a7b6-0c56b3455ee0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a92419-072f-4c05-9eef-556eaf3391e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "# Import pytorch for creating neural networks\n",
    "import torch\n",
    "# Import nn module for creating neural networks\n",
    "import torch.nn as nn\n",
    "# import dataloader for loading data\n",
    "from torch.utils.data import DataLoader\n",
    "# Import transforms\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef48875-91b5-4216-abf5-d23b2c9d3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm\n",
    "from tqdm import tqdm\n",
    "# Import torch summary to get a summary of the model\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b89f21d-7d15-4be3-ac2f-51b1b8187e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions for training the models\n",
    "# Import the discriminators\n",
    "from Models.Discriminators import *\n",
    "# Import the generators\n",
    "from Models.Generators import *\n",
    "# Import the loss functions\n",
    "from Models.Loss_functions import disc_loss, gen_loss_complete\n",
    "\n",
    "# Import the function to load the data\n",
    "from Data.Dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "030ff0a2-1805-434f-b244-aa63f30be362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the visualization function\n",
    "from Utils.visualize_images import visualize_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1db36ed-91ba-4e47-9293-4fa50c70a29c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71aff5b3-5545-42a0-b87f-7640adf6af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Display the device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afca9bee-2be4-47d5-824a-69c6ff445ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model training parameters\n",
    "# Set the number of epochs\n",
    "NUM_EPOCHS = 201\n",
    "# Set the training batch size\n",
    "BATCH_SIZE = 1\n",
    "# Set the learning rate to be used for the optimizers\n",
    "LEARNING_RATE = 0.0002\n",
    "# The size of the images after being loaded\n",
    "LOAD_SHAPE = 286\n",
    "# The size of the images after being cropped\n",
    "CROPPED_SHAPE = 256\n",
    "# Set seed\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86706330-f921-490d-b78d-3172566113e0",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44a0cd6-1907-4009-861f-c30dc63a9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to be applied to images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(LOAD_SHAPE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(CROPPED_SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1125d48f-a526-416d-9dbf-acfaa1504eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = LoadDataset(\"Data/apple2orange\", transform  = transform, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5e4165-0bbb-471f-9364-07bcc7100c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2271a021-b20e-4a8d-af7e-4d5f5a68e626",
   "metadata": {},
   "source": [
    "## Function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7814feb-531b-4909-b7bd-250527e2bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialize the weights\n",
    "def weights_init(m):\n",
    "    # Check if the current layer is a Conv2d or ConvTranspose2d\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        # Apply weights sampled from a normal distribution\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    # Check if the current layer is a normalization layer\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        # Apply weights sampled from a normal distribution\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        # Set the bias as zero\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fdd9586-a7e7-4a0b-a56f-ff34681f11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generators\n",
    "gen_XY = CycleGAN_Generator(3, 64, 3 ).to(device)\n",
    "gen_YX = CycleGAN_Generator(3, 64, 3 ).to(device)\n",
    "# Create the optimizer for the generators\n",
    "gen_opt = torch.optim.Adam(list(gen_XY.parameters()) + list(gen_YX.parameters()), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Create discriminator X and it's optimizer\n",
    "disc_X = CycleGAN_Discriminator(3, 64).to(device)\n",
    "disc_X_opt = torch.optim.Adam(disc_X.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "# Create discriminator Y and it's optimizer\n",
    "disc_Y = CycleGAN_Discriminator(3, 64).to(device)\n",
    "disc_Y_opt = torch.optim.Adam(disc_Y.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "# Set whether to use a checkpoint and continue from there or start training from scratch\n",
    "load_model = False\n",
    "if load_model == True:\n",
    "    # Load the model weights and optimizer \n",
    "    CycleGAN_dict = torch.load(\"Model Weights/CycleGAN/CycleGAN_epoch100.pth\")\n",
    "    # Apply the weights and optimizer\n",
    "    gen_XY.load_state_dict(CycleGAN_dict['gen_XY'])\n",
    "    gen_YX.load_state_dict(CycleGAN_dict['gen_YX'])\n",
    "    gen_opt.load_state_dict(CycleGAN_dict['gen_opt'])\n",
    "    disc_X.load_state_dict(CycleGAN_dict['disc_X'])\n",
    "    disc_Y.load_state_dict(CycleGAN_dict['disc_Y'])\n",
    "    disc_X_opt.load_state_dict(CycleGAN_dict['disc_X_opt'])\n",
    "    disc_Y_opt.load_state_dict(CycleGAN_dict['disc_Y_opt'])\n",
    "else:\n",
    "    # Apply the weights to the generators and discriminators sampled from a normal distribution\n",
    "    gen_XY = gen_XY.apply(weights_init)\n",
    "    gen_YX = gen_YX.apply(weights_init)\n",
    "    disc_X = disc_X.apply(weights_init)\n",
    "    disc_Y = disc_Y.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3ecaea-648e-49b6-9c2c-05b495aa4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "loss_func_adversarial = nn.MSELoss()\n",
    "loss_func_cycle = nn.L1Loss()\n",
    "loss_func_identity = nn.L1Loss()\n",
    "\n",
    "# Define the weights for the loss functions\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49fc9df3-167e-4936-a518-93898a3c36f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "      InitialBlock-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3        [-1, 128, 128, 128]          73,856\n",
      "    InstanceNorm2d-4        [-1, 128, 128, 128]               0\n",
      "              ReLU-5        [-1, 128, 128, 128]               0\n",
      "         DownBlock-6        [-1, 128, 128, 128]               0\n",
      "            Conv2d-7          [-1, 256, 64, 64]         295,168\n",
      "    InstanceNorm2d-8          [-1, 256, 64, 64]               0\n",
      "              ReLU-9          [-1, 256, 64, 64]               0\n",
      "        DownBlock-10          [-1, 256, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-12          [-1, 256, 64, 64]               0\n",
      "             ReLU-13          [-1, 256, 64, 64]               0\n",
      "           Conv2d-14          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-15          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-18          [-1, 256, 64, 64]               0\n",
      "             ReLU-19          [-1, 256, 64, 64]               0\n",
      "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-21          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-22          [-1, 256, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-24          [-1, 256, 64, 64]               0\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "           Conv2d-26          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-27          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-28          [-1, 256, 64, 64]               0\n",
      "           Conv2d-29          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-30          [-1, 256, 64, 64]               0\n",
      "             ReLU-31          [-1, 256, 64, 64]               0\n",
      "           Conv2d-32          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-33          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-34          [-1, 256, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-36          [-1, 256, 64, 64]               0\n",
      "             ReLU-37          [-1, 256, 64, 64]               0\n",
      "           Conv2d-38          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-39          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-40          [-1, 256, 64, 64]               0\n",
      "           Conv2d-41          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-42          [-1, 256, 64, 64]               0\n",
      "             ReLU-43          [-1, 256, 64, 64]               0\n",
      "           Conv2d-44          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-45          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-46          [-1, 256, 64, 64]               0\n",
      "           Conv2d-47          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-48          [-1, 256, 64, 64]               0\n",
      "             ReLU-49          [-1, 256, 64, 64]               0\n",
      "           Conv2d-50          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-51          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-52          [-1, 256, 64, 64]               0\n",
      "           Conv2d-53          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-54          [-1, 256, 64, 64]               0\n",
      "             ReLU-55          [-1, 256, 64, 64]               0\n",
      "           Conv2d-56          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-57          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-58          [-1, 256, 64, 64]               0\n",
      "           Conv2d-59          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-60          [-1, 256, 64, 64]               0\n",
      "             ReLU-61          [-1, 256, 64, 64]               0\n",
      "           Conv2d-62          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-63          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-64          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-65        [-1, 128, 128, 128]         295,040\n",
      "   InstanceNorm2d-66        [-1, 128, 128, 128]               0\n",
      "             ReLU-67        [-1, 128, 128, 128]               0\n",
      "          UpBlock-68        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-69         [-1, 64, 256, 256]          73,792\n",
      "   InstanceNorm2d-70         [-1, 64, 256, 256]               0\n",
      "             ReLU-71         [-1, 64, 256, 256]               0\n",
      "          UpBlock-72         [-1, 64, 256, 256]               0\n",
      "           Conv2d-73          [-1, 3, 256, 256]           9,411\n",
      "     InitialBlock-74          [-1, 3, 256, 256]               0\n",
      "             Tanh-75          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 11,378,179\n",
      "Trainable params: 11,378,179\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 788.50\n",
      "Params size (MB): 43.40\n",
      "Estimated Total Size (MB): 832.65\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "      InitialBlock-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3        [-1, 128, 128, 128]          73,856\n",
      "    InstanceNorm2d-4        [-1, 128, 128, 128]               0\n",
      "              ReLU-5        [-1, 128, 128, 128]               0\n",
      "         DownBlock-6        [-1, 128, 128, 128]               0\n",
      "            Conv2d-7          [-1, 256, 64, 64]         295,168\n",
      "    InstanceNorm2d-8          [-1, 256, 64, 64]               0\n",
      "              ReLU-9          [-1, 256, 64, 64]               0\n",
      "        DownBlock-10          [-1, 256, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-12          [-1, 256, 64, 64]               0\n",
      "             ReLU-13          [-1, 256, 64, 64]               0\n",
      "           Conv2d-14          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-15          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-18          [-1, 256, 64, 64]               0\n",
      "             ReLU-19          [-1, 256, 64, 64]               0\n",
      "           Conv2d-20          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-21          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-22          [-1, 256, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-24          [-1, 256, 64, 64]               0\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "           Conv2d-26          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-27          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-28          [-1, 256, 64, 64]               0\n",
      "           Conv2d-29          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-30          [-1, 256, 64, 64]               0\n",
      "             ReLU-31          [-1, 256, 64, 64]               0\n",
      "           Conv2d-32          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-33          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-34          [-1, 256, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-36          [-1, 256, 64, 64]               0\n",
      "             ReLU-37          [-1, 256, 64, 64]               0\n",
      "           Conv2d-38          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-39          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-40          [-1, 256, 64, 64]               0\n",
      "           Conv2d-41          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-42          [-1, 256, 64, 64]               0\n",
      "             ReLU-43          [-1, 256, 64, 64]               0\n",
      "           Conv2d-44          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-45          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-46          [-1, 256, 64, 64]               0\n",
      "           Conv2d-47          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-48          [-1, 256, 64, 64]               0\n",
      "             ReLU-49          [-1, 256, 64, 64]               0\n",
      "           Conv2d-50          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-51          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-52          [-1, 256, 64, 64]               0\n",
      "           Conv2d-53          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-54          [-1, 256, 64, 64]               0\n",
      "             ReLU-55          [-1, 256, 64, 64]               0\n",
      "           Conv2d-56          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-57          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-58          [-1, 256, 64, 64]               0\n",
      "           Conv2d-59          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-60          [-1, 256, 64, 64]               0\n",
      "             ReLU-61          [-1, 256, 64, 64]               0\n",
      "           Conv2d-62          [-1, 256, 64, 64]         590,080\n",
      "   InstanceNorm2d-63          [-1, 256, 64, 64]               0\n",
      "    ResidualBlock-64          [-1, 256, 64, 64]               0\n",
      "  ConvTranspose2d-65        [-1, 128, 128, 128]         295,040\n",
      "   InstanceNorm2d-66        [-1, 128, 128, 128]               0\n",
      "             ReLU-67        [-1, 128, 128, 128]               0\n",
      "          UpBlock-68        [-1, 128, 128, 128]               0\n",
      "  ConvTranspose2d-69         [-1, 64, 256, 256]          73,792\n",
      "   InstanceNorm2d-70         [-1, 64, 256, 256]               0\n",
      "             ReLU-71         [-1, 64, 256, 256]               0\n",
      "          UpBlock-72         [-1, 64, 256, 256]               0\n",
      "           Conv2d-73          [-1, 3, 256, 256]           9,411\n",
      "     InitialBlock-74          [-1, 3, 256, 256]               0\n",
      "             Tanh-75          [-1, 3, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 11,378,179\n",
      "Trainable params: 11,378,179\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 788.50\n",
      "Params size (MB): 43.40\n",
      "Estimated Total Size (MB): 832.65\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "      InitialBlock-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 128, 128]          65,600\n",
      "    InstanceNorm2d-4         [-1, 64, 128, 128]               0\n",
      "         LeakyReLU-5         [-1, 64, 128, 128]               0\n",
      "         DownBlock-6         [-1, 64, 128, 128]               0\n",
      "            Conv2d-7          [-1, 128, 64, 64]         131,200\n",
      "    InstanceNorm2d-8          [-1, 128, 64, 64]               0\n",
      "         LeakyReLU-9          [-1, 128, 64, 64]               0\n",
      "        DownBlock-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]         524,544\n",
      "   InstanceNorm2d-12          [-1, 256, 32, 32]               0\n",
      "        LeakyReLU-13          [-1, 256, 32, 32]               0\n",
      "        DownBlock-14          [-1, 256, 32, 32]               0\n",
      "           Conv2d-15          [-1, 512, 31, 31]       2,097,664\n",
      "   InstanceNorm2d-16          [-1, 512, 31, 31]               0\n",
      "        LeakyReLU-17          [-1, 512, 31, 31]               0\n",
      "        DownBlock-18          [-1, 512, 31, 31]               0\n",
      "           Conv2d-19            [-1, 1, 30, 30]           8,193\n",
      "================================================================\n",
      "Total params: 2,836,673\n",
      "Trainable params: 2,836,673\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 135.02\n",
      "Params size (MB): 10.82\n",
      "Estimated Total Size (MB): 146.59\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]           9,472\n",
      "      InitialBlock-2         [-1, 64, 256, 256]               0\n",
      "            Conv2d-3         [-1, 64, 128, 128]          65,600\n",
      "    InstanceNorm2d-4         [-1, 64, 128, 128]               0\n",
      "         LeakyReLU-5         [-1, 64, 128, 128]               0\n",
      "         DownBlock-6         [-1, 64, 128, 128]               0\n",
      "            Conv2d-7          [-1, 128, 64, 64]         131,200\n",
      "    InstanceNorm2d-8          [-1, 128, 64, 64]               0\n",
      "         LeakyReLU-9          [-1, 128, 64, 64]               0\n",
      "        DownBlock-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 32, 32]         524,544\n",
      "   InstanceNorm2d-12          [-1, 256, 32, 32]               0\n",
      "        LeakyReLU-13          [-1, 256, 32, 32]               0\n",
      "        DownBlock-14          [-1, 256, 32, 32]               0\n",
      "           Conv2d-15          [-1, 512, 31, 31]       2,097,664\n",
      "   InstanceNorm2d-16          [-1, 512, 31, 31]               0\n",
      "        LeakyReLU-17          [-1, 512, 31, 31]               0\n",
      "        DownBlock-18          [-1, 512, 31, 31]               0\n",
      "           Conv2d-19            [-1, 1, 30, 30]           8,193\n",
      "================================================================\n",
      "Total params: 2,836,673\n",
      "Trainable params: 2,836,673\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 135.02\n",
      "Params size (MB): 10.82\n",
      "Estimated Total Size (MB): 146.59\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the summary of the Generator XY\n",
    "#summary(gen_XY, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Generator YX\n",
    "#summary(gen_YX, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Discriminator X\n",
    "#summary(disc_X, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Discriminator Y\n",
    "#summary(disc_Y, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eea36ab-306e-444a-a78c-23318b3a6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "visl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "676f31c8-cab5-45ca-9c74-3c7b1fbe379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to train the CycleGAN\n",
    "def train_CycleGAN():\n",
    "    \"\"\"\n",
    "    Function to train CycleGAN. Doesn't take any inputs.\n",
    "    \n",
    "    Outputs: Saves the model to disk\n",
    "             Displays the real and generated images after every few steps\n",
    "             Prints the mean generator and discriminator losses\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define variables to keep track of mean generator and discriminator losses\n",
    "    loss_generator_mean = 0\n",
    "    loss_discriminator_mean = 0\n",
    "    # Create a counter that to keep track of how many images have been processed\n",
    "    # and to display real and generated images after certain images have been processed\n",
    "    disp = 1\n",
    "    \n",
    "    # Keep training for a certain number of epochs\n",
    "    for epoch in range(1, NUM_EPOCHS):\n",
    "        # Use the tqdm to load the data\n",
    "        for real_img_X, real_img_Y in tqdm(dataloader):\n",
    "            # Move the images to the device\n",
    "            real_img_X = real_img_X.to(device)\n",
    "            real_img_Y = real_img_Y.to(device)\n",
    "                   \n",
    "            # Update the generators\n",
    "            # Set the gradients to zero\n",
    "            gen_opt.zero_grad()\n",
    "            # Compute the generator loss\n",
    "            loss_gen = gen_loss_complete(real_img_X, real_img_Y,\n",
    "                                         gen_XY, gen_YX, disc_X, disc_Y,  \n",
    "                                         loss_func_adversarial, loss_func_cycle, loss_func_identity, \n",
    "                                         lambda_cycle, lambda_identity, \n",
    "                                         add_identity_loss = True)\n",
    "            # Perform backpropogation for the generator\n",
    "            loss_gen.backward()\n",
    "            # Update the generators by taking an optimization step\n",
    "            gen_opt.step()\n",
    "\n",
    "            # Update disc_X \n",
    "            # Set the gradients to zero\n",
    "            disc_X_opt.zero_grad()\n",
    "            # Generate a fake image in domain X\n",
    "            with torch.no_grad():\n",
    "                fake_img_X = gen_YX(real_img_Y)\n",
    "            # Compute the loss\n",
    "            loss_disc_X = disc_loss(real_img_X, fake_img_X.detach(), disc_X, loss_func_adversarial)\n",
    "            # Perform backpropogation for disc_X\n",
    "            loss_disc_X.backward(retain_graph=True)\n",
    "            # Update disc_X opt\n",
    "            disc_X_opt.step() \n",
    "            \n",
    "            # Update disc_Y\n",
    "            # Set the gradients to zero\n",
    "            disc_Y_opt.zero_grad() \n",
    "            # Generate a fake image in domain Y\n",
    "            with torch.no_grad():\n",
    "                fake_img_Y = gen_XY(real_img_X)\n",
    "            # Compute the loss\n",
    "            loss_disc_Y = disc_loss(real_img_Y, fake_img_Y.detach(), disc_Y, loss_func_adversarial)\n",
    "            # Perform backpropogation for disc_Y\n",
    "            loss_disc_Y.backward(retain_graph=True)\n",
    "            # Update disc_Y opt\n",
    "            disc_Y_opt.step() \n",
    "            \n",
    "            # Compute the mean generator and discriminator loss\n",
    "            loss_generator_mean = loss_gen.item()/disp\n",
    "            loss_discriminator_mean = ( loss_disc_X + loss_disc_Y ).item() / disp\n",
    "            \n",
    "            # Check if the images are to be visualized\n",
    "            if visl == True:\n",
    "                # Code for visualization\n",
    "                if disp % 10 == 0:\n",
    "                    # Visualize the images\n",
    "                    # The transform applied to the images 0.5 and divides by 0.5\n",
    "                    # To un-transform we have to add 1 and divide by 2\n",
    "                    visualize_images( (real_img_X +1 ) / 2, (real_img_Y + 1) / 2, (fake_img_X + 1) / 2, (fake_img_Y + 1) / 2)\n",
    "                    # Display the mean generator and discriminator losses\n",
    "                    print(f\"Display step is: {disp}\\n\"\n",
    "                      f\"The average discriminator loss is: {loss_discriminator_mean}\\n\"\n",
    "                      f\"The average generator loss is: {loss_generator_mean}\\n\")\n",
    "            # Increase the display counter\n",
    "            disp+= 1\n",
    "        # For loop for loading data using tqdm ends here\n",
    "        \n",
    "        # Print the generator and discriminator loss at each epoch\n",
    "        print(f\"Epoch is: {epoch}\\n\"\n",
    "              f\"The average discriminator loss is: {loss_discriminator_mean}\\n\"\n",
    "              f\"The average generator loss is: {loss_generator_mean}\\n\")\n",
    "            \n",
    "        # Save the model after every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            # Define a save path\n",
    "            save_path = \"Model Weights/CycleGAN/\"\n",
    "            # Create a variable storing the current checkpoint name\n",
    "            name_model_epoch = f\"CycleGAN_epoch{epoch}.pth\"\n",
    "            # Create a directory if it does not exist\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path, exist_ok = True)\n",
    "            # Save the model to this directory\n",
    "            torch.save({\n",
    "                    'gen_XY': gen_XY.state_dict(),\n",
    "                    'gen_YX': gen_YX.state_dict(),\n",
    "                    'gen_opt': gen_opt.state_dict(),\n",
    "                    'disc_X': disc_X.state_dict(),\n",
    "                    'disc_Y': disc_Y.state_dict(),\n",
    "                    'disc_X_opt':disc_X_opt.state_dict(),\n",
    "                    'disc_Y_opt':disc_Y_opt.state_dict()\n",
    "                }, save_path + name_model_epoch)\n",
    "# End of function definition        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e06619ef-199a-4ac5-92c9-948bc7f26d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 45/1067 [00:26<10:00,  1.70it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11960\\604000513.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the CycleGAN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_CycleGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11960\\4269148610.py\u001b[0m in \u001b[0;36mtrain_CycleGAN\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mloss_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m# Update the generators by taking an optimization step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mgen_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;31m# Update disc_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             adam(params_with_grad,\n\u001b[0m\u001b[0;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     func(params,\n\u001b[0m\u001b[0;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the CycleGAN\n",
    "train_CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13acc68a-bf6e-42ab-8b12-f9c426e85113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train_CycleGAN.ipynb to script\n",
      "[NbConvertApp] Writing 9975 bytes to train_CycleGAN.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script --no-prompt train_CycleGAN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306f110-00fe-4c24-9128-582970842544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
