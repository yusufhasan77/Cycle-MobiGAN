{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c6186b-e07b-4850-b67a-61034a1947db",
   "metadata": {},
   "source": [
    "# CycleGAN_IR_DWS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2938f037-e0a7-4bf9-a7b6-0c56b3455ee0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0a92419-072f-4c05-9eef-556eaf3391e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "# Import pytorch for creating neural networks\n",
    "import torch\n",
    "# Import nn module for creating neural networks\n",
    "import torch.nn as nn\n",
    "# import dataloader for loading data\n",
    "from torch.utils.data import DataLoader\n",
    "# Import transforms\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef48875-91b5-4216-abf5-d23b2c9d3c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tqdm\n",
    "from tqdm import tqdm\n",
    "# Import torch summary to get a summary of the model\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b89f21d-7d15-4be3-ac2f-51b1b8187e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the functions for training the models\n",
    "# Import the discriminators\n",
    "from Models.Discriminators import *\n",
    "# Import the generators\n",
    "from Models.Generators import *\n",
    "# Import the loss functions\n",
    "from Models.Loss_functions import disc_loss, gen_loss_complete\n",
    "\n",
    "# Import the function to load the data\n",
    "from Data.Dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030ff0a2-1805-434f-b244-aa63f30be362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the visualization function\n",
    "from Utils.visualize_images import visualize_images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1db36ed-91ba-4e47-9293-4fa50c70a29c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71aff5b3-5545-42a0-b87f-7640adf6af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Display the device\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afca9bee-2be4-47d5-824a-69c6ff445ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28fa725d570>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model training parameters\n",
    "# Set the number of epochs\n",
    "NUM_EPOCHS = 201\n",
    "# Set the training batch size\n",
    "BATCH_SIZE = 1\n",
    "# Set the learning rate to be used for the optimizers\n",
    "LEARNING_RATE = 0.0002\n",
    "# The size of the images after being loaded\n",
    "LOAD_SHAPE = 286\n",
    "# The size of the images after being cropped\n",
    "CROPPED_SHAPE = 256\n",
    "# Set seed\n",
    "torch.manual_seed(7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86706330-f921-490d-b78d-3172566113e0",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f44a0cd6-1907-4009-861f-c30dc63a9575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transformation to be applied to images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(LOAD_SHAPE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(CROPPED_SHAPE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1125d48f-a526-416d-9dbf-acfaa1504eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = LoadDataset(\"Data/apple2orange\", transform  = transform, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea5e4165-0bbb-471f-9364-07bcc7100c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataloader\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2271a021-b20e-4a8d-af7e-4d5f5a68e626",
   "metadata": {},
   "source": [
    "## Function for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7814feb-531b-4909-b7bd-250527e2bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialize the weights\n",
    "def weights_init(m):\n",
    "    # Check if the current layer is a Conv2d or ConvTranspose2d\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        # Apply weights sampled from a normal distribution\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    # Check if the current layer is a normalization layer\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        # Apply weights sampled from a normal distribution\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        # Set the bias as zero\n",
    "        torch.nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fdd9586-a7e7-4a0b-a56f-ff34681f11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generators\n",
    "gen_XY = CycleGAN_Generator_DWS(3, 64, 3 ).to(device)\n",
    "gen_YX = CycleGAN_Generator_DWS(3, 64, 3 ).to(device)\n",
    "# Create the optimizer for the generators\n",
    "gen_opt = torch.optim.Adam(list(gen_XY.parameters()) + list(gen_YX.parameters()), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Create the discriminators\n",
    "# Create discriminator X and it's optimizer\n",
    "disc_X = CycleGAN_Discriminator_DWS(3, 64).to(device)\n",
    "disc_X_opt = torch.optim.Adam(disc_X.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "# Create discriminator Y and it's optimizer\n",
    "disc_Y = CycleGAN_Discriminator_DWS(3, 64).to(device)\n",
    "disc_Y_opt = torch.optim.Adam(disc_Y.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "\n",
    "# Set whether to use a checkpoint and continue from there or start training from scratch\n",
    "load_model = False\n",
    "if load_model == True:\n",
    "    # Load the model weights and optimizer \n",
    "    CycleGAN_dict = torch.load(\"Model Weights/CycleGAN_DWS/CycleGAN_DWS_epoch100.pth\")\n",
    "    # Apply the weights and optimizer\n",
    "    gen_XY.load_state_dict(CycleGAN_dict['gen_XY'])\n",
    "    gen_YX.load_state_dict(CycleGAN_dict['gen_YX'])\n",
    "    gen_opt.load_state_dict(CycleGAN_dict['gen_opt'])\n",
    "    disc_X.load_state_dict(CycleGAN_dict['disc_X'])\n",
    "    disc_Y.load_state_dict(CycleGAN_dict['disc_Y'])\n",
    "    disc_X_opt.load_state_dict(CycleGAN_dict['disc_X_opt'])\n",
    "    disc_Y_opt.load_state_dict(CycleGAN_dict['disc_Y_opt'])\n",
    "else:\n",
    "    # Apply the weights to the generators and discriminators sampled from a normal distribution\n",
    "    gen_XY = gen_XY.apply(weights_init)\n",
    "    gen_YX = gen_YX.apply(weights_init)\n",
    "    disc_X = disc_X.apply(weights_init)\n",
    "    disc_Y = disc_Y.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3ecaea-648e-49b6-9c2c-05b495aa4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "loss_func_adversarial = nn.MSELoss()\n",
    "loss_func_cycle = nn.L1Loss()\n",
    "loss_func_identity = nn.L1Loss()\n",
    "\n",
    "# Define the weights for the loss functions\n",
    "lambda_cycle = 10\n",
    "lambda_identity = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5971c750-ee0a-4ded-9533-8a80f2273bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary of the Generator XY\n",
    "#summary(gen_XY, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Generator YX\n",
    "#summary(gen_YX, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Discriminator X\n",
    "#summary(disc_X, (3, 256, 256))\n",
    "\n",
    "# Print the summary of the Discriminator Y\n",
    "#summary(disc_Y, (3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0eea36ab-306e-444a-a78c-23318b3a6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "visl = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "676f31c8-cab5-45ca-9c74-3c7b1fbe379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to train the CycleGAN\n",
    "def train_CycleGAN_DWS():\n",
    "    \"\"\"\n",
    "    Function to train CycleGAN with inverted residual blocks instead of residual blocks. \n",
    "    Doesn't take any inputs.\n",
    "    \n",
    "    Outputs: Saves the model to disk\n",
    "             Displays the real and generated images after every few steps (If chosen)\n",
    "             Prints the mean generator and discriminator losses after every epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define variables to keep track of mean generator and discriminator losses\n",
    "    loss_generator_mean = 0\n",
    "    loss_discriminator_mean = 0\n",
    "    # Create a counter that to keep track of how many images have been processed\n",
    "    # and to display real and generated images after certain images have been processed\n",
    "    disp = 1\n",
    "    \n",
    "    # Keep training for a certain number of epochs\n",
    "    for epoch in range(1, NUM_EPOCHS):\n",
    "        # Use the tqdm to load the data\n",
    "        for real_img_X, real_img_Y in tqdm(dataloader):\n",
    "            # Move the images to the device\n",
    "            real_img_X = real_img_X.to(device)\n",
    "            real_img_Y = real_img_Y.to(device)\n",
    "\n",
    "            # UPDATE THE GENS\n",
    "            # Set the gradients to zero\n",
    "            gen_opt.zero_grad()\n",
    "            # Compute the generator loss\n",
    "            loss_gen = gen_loss_complete(real_img_X, real_img_Y,\n",
    "                                         gen_XY, gen_YX, disc_X, disc_Y,  \n",
    "                                         loss_func_adversarial, loss_func_cycle, loss_func_identity, \n",
    "                                         lambda_cycle, lambda_identity, \n",
    "                                         add_identity_loss = True)\n",
    "            # Perform backpropogation for the generator\n",
    "            loss_gen.backward()\n",
    "            # Update the generators by taking an optimization step\n",
    "            gen_opt.step()\n",
    "            \n",
    "            # UPDATE THE DISCS\n",
    "            # Update disc_X \n",
    "            # Set the gradients to zero\n",
    "            disc_X_opt.zero_grad()\n",
    "            # Generate a fake image in domain X\n",
    "            with torch.no_grad():\n",
    "                fake_img_X = gen_YX(real_img_Y)\n",
    "            # Compute the loss\n",
    "            loss_disc_X = disc_loss(real_img_X, fake_img_X.detach(), disc_X, loss_func_adversarial)\n",
    "            # Perform backpropogation for disc_X\n",
    "            loss_disc_X.backward(retain_graph=True)\n",
    "            # Update disc_X opt\n",
    "            disc_X_opt.step() \n",
    "            \n",
    "            # Update disc_Y\n",
    "            # Set the gradients to zero\n",
    "            disc_Y_opt.zero_grad() \n",
    "            # Generate a fake image in domain Y\n",
    "            with torch.no_grad():\n",
    "                fake_img_Y = gen_XY(real_img_X)\n",
    "            # Compute the loss\n",
    "            loss_disc_Y = disc_loss(real_img_Y, fake_img_Y.detach(), disc_Y, loss_func_adversarial)\n",
    "            # Perform backpropogation for disc_Y\n",
    "            loss_disc_Y.backward(retain_graph=True)\n",
    "            # Update disc_Y opt\n",
    "            disc_Y_opt.step() \n",
    "            \n",
    "            # Compute the mean generator and discriminator loss\n",
    "            loss_generator_mean = loss_gen.item()/disp\n",
    "            loss_discriminator_mean = ( loss_disc_X + loss_disc_Y ).item() / disp\n",
    "            \n",
    "            # Check if the images are to be visualized\n",
    "            if visl == True:\n",
    "                # Code for visualization\n",
    "                if disp % 10 == 0:\n",
    "                    # Visualize the images\n",
    "                    # The transform applied to the images 0.5 and divides by 0.5\n",
    "                    # To un-transform we have to add 1 and divide by 2\n",
    "                    visualize_images( (real_img_X +1 ) / 2, (real_img_Y + 1) / 2, (fake_img_X + 1) / 2, (fake_img_Y + 1) / 2)\n",
    "                    # Display the mean generator and discriminator losses\n",
    "                    print(f\"Display step is: {disp}\\n\"\n",
    "                      f\"The average discriminator loss is: {loss_discriminator_mean}\\n\"\n",
    "                      f\"The average generator loss is: {loss_generator_mean}\\n\")\n",
    "            # Increase the display counter\n",
    "            disp+= 1\n",
    "        # For loop for loading data using tqdm ends here\n",
    "        \n",
    "        # Print the generator and discriminator loss at each epoch\n",
    "        print(f\"Epoch is: {epoch}\\n\"\n",
    "              f\"The average discriminator loss is: {loss_discriminator_mean}\\n\"\n",
    "              f\"The average generator loss is: {loss_generator_mean}\\n\")\n",
    "            \n",
    "        # Save the model after every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            # Define a save path\n",
    "            save_path = \"Model Weights/CycleGAN_DWS/\"\n",
    "            # Create a variable storing the current checkpoint name\n",
    "            name_model_epoch = f\"CycleGAN_DWS_epoch{epoch}.pth\"\n",
    "            # Create a directory if it does not exist\n",
    "            if not os.path.exists(save_path):\n",
    "                os.makedirs(save_path, exist_ok = True)\n",
    "            # Save the model to this directory\n",
    "            torch.save({\n",
    "                    'gen_XY': gen_XY.state_dict(),\n",
    "                    'gen_YX': gen_YX.state_dict(),\n",
    "                    'gen_opt': gen_opt.state_dict(),\n",
    "                    'disc_X': disc_X.state_dict(),\n",
    "                    'disc_Y': disc_Y.state_dict(),\n",
    "                    'disc_X_opt':disc_X_opt.state_dict(),\n",
    "                    'disc_Y_opt':disc_Y_opt.state_dict()\n",
    "                }, save_path + name_model_epoch)\n",
    "# End of function definition        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06619ef-199a-4ac5-92c9-948bc7f26d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_CycleGAN_DWS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the CycleGAN\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_CycleGAN_DWS()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_CycleGAN_DWS' is not defined"
     ]
    }
   ],
   "source": [
    "# Train the CycleGAN\n",
    "train_CycleGAN_DWS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13acc68a-bf6e-42ab-8b12-f9c426e85113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train_CycleGAN_DWS.ipynb to script\n",
      "[NbConvertApp] Writing 10164 bytes to train_CycleGAN_DWS.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script --no-prompt train_CycleGAN_DWS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5306f110-00fe-4c24-9128-582970842544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
